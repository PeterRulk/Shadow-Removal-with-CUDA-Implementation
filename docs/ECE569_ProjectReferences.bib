@InProceedings{Akoglu,
  author    = {Richter, Edward and Raettig, Ryan and Mack, Joshua and Valancius, Spencer and Unal, Burak and Akoglu, Ali},
  booktitle = {2019 IEEE/ACS 16th International Conference on Computer Systems and Applications (AICCSA)},
  title     = {Accelerated Shadow Detection and Removal Method},
  year      = {2019},
  month     = {Nov},
  pages     = {1-8},
  abstract  = {Shadows can have a negative effect on the ability of computer vision techniques for object detection, tracking, and recognition. Therefore, ability to remove shadows and byproducts of illumination is an important problem to enable effective object recognition actions. As applications move into levels of higher information extraction and higher required processing speeds, efficient and sophisticated shadow detection and removal becomes even more necessary. In this study we propose a shadow removal method, parallelize using a Tesla P100 GPU, and achieve a speedup of 21.67× on an 18 megapixel (MP) resolution image compared to the same method implemented in Matlab.},
  doi       = {10.1109/AICCSA47632.2019.9035242},
  issn      = {2161-5330},
  keywords  = {Convolution;Kernel;Graphics processing units;Gray-scale;Mathematical model;Computer vision;Histograms},
}

 
@Article{Qu2023,
  author   = {Qu, Haicheng and Tong, Chang and Liu, Wanjun},
  journal  = {Signal, Image and Video Processing},
  title    = {Image shadow removal algorithm guided by progressive attention mechanism},
  year     = {2023},
  issn     = {1863-1711},
  month    = jul,
  number   = {5},
  pages    = {2565--2571},
  volume   = {17},
  abstract = {Current shadow removal algorithms generally require prior knowledge. When restoring dark areas or shadow areas with complex textures, there are problems of incomplete restoration of details and distortion. In this paper, a novel image shadow removal algorithm guided by progressive attention mechanism (PAGAN) was proposed for the residual and incomplete shadow removal of complex objects or dark areas. The algorithm combines an attention mechanism with feature fusion technology, which improves the feature location accuracy and enriches the feature information. First, in the feature extraction stage of the generation network, dilated convolution residual blocks were used with different learning rates for feature extraction to expand the receptive field of the network. Then, a parallel attention mechanism was used in the auto-encoder of the generation network to guide the generation network to compile the details of the shadowless image. Second, in the auto-encoding stage, a multi-layer and multi-scale feature fusion method was applied to incorporate the global semantic information and local detail features. Finally, the series attention mechanism was used to guide the discrimination network to identify the shadowless image generated by the generation network to reduce the loss of key features and enhance the identification ability of the discrimination network. Experiments based on open datasets, SRD and ISTD, indicated good visual effect. The structural similarity index measure value of the algorithm can reach 97.5 \$\${\textbackslash}\%\$\$, the peak signal-to-noise ratio can reach 32.8, and the root mean square error can be reduced to 5.8.},
  doi      = {10.1007/s11760-022-02473-z},
  file     = {:Qu2023 - Image Shadow Removal Algorithm Guided by Progressive Attention Mechanism.html:URL},
  keywords = {Attention mechanism, Feature fusion, Generation discrimination network, Shadow removal},
  language = {en},
  url      = {https://doi.org/10.1007/s11760-022-02473-z},
  urldate  = {2024-02-24},
}

@Article{Benalia2022,
  author   = {S. Benalia and M. Hachama},
  journal  = {Computers & Mathematics with Applications},
  title    = {A nonlocal method for image shadow removal},
  year     = {2022},
  issn     = {0898-1221},
  pages    = {95--103},
  volume   = {107},
  abstract = {This paper proposes a new model for image shadow removal. The model reformulates a recent osmosis model with nonlocal differential operators. This allows to benefit from distant pixels similarities and thus improves restoration results. Some properties of this model are established and discussed, making it suitable for our application. Experimental results show that the nonlocal model obtained very good qualitative and quantitative results compared with state-of-the-art techniques.},
  doi      = {10.1016/j.camwa.2021.12.023},
  keywords = {Image restoration, Shadows removal, Nonlocal differential operators, Energy minimization},
  url      = {https://www.sciencedirect.com/science/article/pii/S0898122121004636},
}

@Article{Zhang2015,
  author   = {Zhang, Ling and Zhang, Qing and Xiao, Chunxia},
  journal  = {IEEE Transactions on Image Processing},
  title    = {Shadow Remover: Image Shadow Removal Based on Illumination Recovering Optimization},
  year     = {2015},
  number   = {11},
  pages    = {4623-4636},
  volume   = {24},
  doi      = {10.1109/TIP.2015.2465159},
  keywords = {Lighting;Image color analysis;Image edge detection;Shape;Optimization methods;Buildings;shadow detection;shadow removal;shadow matting;Shadow detection;shadow removal;shadow matting;patch matching;aerial images},
}

@InProceedings{Le2019,
  author    = {Le, Hieu and Samaras, Dimitris},
  booktitle = {2019 IEEE/CVF International Conference on Computer Vision (ICCV)},
  title     = {Shadow Removal via Shadow Image Decomposition},
  year      = {2019},
  pages     = {8577-8586},
  doi       = {10.1109/ICCV.2019.00867},
  keywords  = {Lighting;Image color analysis;Image decomposition;Machine learning;Computational modeling;Training;Image reconstruction},
}

 
@Article{Wu2020,
  author    = {Wu, Minghu and Chen, Rui and Tong, Ying},
  journal   = {Computational Intelligence and Neuroscience},
  title     = {Shadow {Elimination} {Algorithm} {Using} {Color} and {Texture} {Features}},
  year      = {2020},
  issn      = {1687-5265},
  month     = jan,
  pages     = {e2075781},
  volume    = {2020},
  abstract  = {Shadow detection and removal in real scene images are a significant problem for target detection. This work proposes an improved shadow detection and removal algorithm for urban video surveillance. First, the foreground is detected by background subtraction and the shadow is detected by HSV color space. Using local variance and OTSU method, we obtain the moving targets with texture features. According to the characteristics of shadow in HSV space and texture feature, the shadow is detected and removed to eliminate the shadow interference for the subsequent processing of moving targets. Finally, we embed our algorithm into C/S framework based on the HTML5 web socket protocol. Both the experimental and actual operation results show that the proposed algorithm is efficient and robust in target detection and shadow detection and removal under different scenes.},
  doi       = {10.1155/2020/2075781},
  file      = {:Wu2020 - Shadow Elimination Algorithm Using Color and Texture Features.pdf:PDF},
  language  = {en},
  publisher = {Hindawi},
  url       = {https://www.hindawi.com/journals/cin/2020/2075781/},
  urldate   = {2024-02-24},
}

 
@Electronic{Dexon,
  language     = {en-US},
  month        = apr,
  organization = {DEXON Systems},
  title        = {What are {RGB} and {YUV} color spaces?},
  url          = {https://dexonsystems.com/blog/rgb-yuv-color-spaces},
  year         = {2022},
  abstract     = {Color spaces can be tricky things to navigate but are essential for producing vibrant and attractive images and videos that pop with color.},
  journal      = {DEXON Systems},
}

@Electronic{CUDAv12-4,
  month        = apr,
  organization = {NVIDIA Corporation},
  title        = {{CUDA Toolkit Documentation 12.4 Update 1}},
  url          = {https://docs.nvidia.com/cuda/#cuda-toolkit-documentation-v12-4},
  year         = {2024},
  journal      = {NVIDIA Corporation},
}

 
@Electronic{Wiki-YUV,
  language     = {en},
  month        = apr,
  note         = {Page Version ID: 1220238267},
  organization = {Wikimedia Foundation, Inc.},
  title        = {Y′{UV}},
  url          = {https://en.wikipedia.org/wiki/Y′UV},
  year         = {2024},
  abstract     = {Y′UV, also written YUV, is the color model found in the PAL analogue color TV standard (excluding PAL-N). A color is described as a Y′ component (luma) and two chroma components U and V. The prime symbol (') denotes that the luma is calculated from gamma-corrected RGB input and that it is different from true luminance. Today, the term YUV is commonly used in the computer industry to describe colorspaces that are encoded using YCbCr. In TV formats, color information (U and V) was added separately via a subcarrier so that a black-and-white receiver would still be able to receive and display a color picture transmission in the receiver's native black-and-white format, with no need for extra transmission bandwidth. As for etymology, Y, Y′, U, and V are not abbreviations. The use of the letter Y for luminance can be traced back to the choice of XYZ primaries. This lends itself naturally to the usage of the same letter in luma (Y′), which approximates a perceptually uniform correlate of luminance. Likewise, U and V were chosen to differentiate the U and V axes from those in other spaces, such as the x and y chromaticity space. See the equations below or compare the historical development of the math.},
  copyright    = {Creative Commons Attribution-ShareAlike License},
  journal      = {Wikimedia Foundation, Inc.},
}

 
@Electronic{Dynamsoft,
  language     = {en},
  month        = may,
  organization = {Dynamsoft Corporation},
  title        = {Image {Processing} 101 {Chapter} 1.3: {Color} {Space} {Conversion}},
  url          = {https://www.dynamsoft.com/blog/insights/image-processing/image-processing-101-color-space-conversion/},
  year         = {2019},
  abstract     = {Continue with our image processing 101 series, learn about how to convert color images to grayscale and black/white images.},
  journal      = {Dynamsoft Blog},
  shorttitle   = {Image {Processing} 101 {Chapter} 1.3},
}

@Article{Otsu1979,
  author   = {Otsu, Nobuyuki},
  journal  = {IEEE Transactions on Systems, Man, and Cybernetics},
  title    = {A Threshold Selection Method from Gray-Level Histograms},
  year     = {1979},
  issn     = {2168-2909},
  month    = {Jan},
  number   = {1},
  pages    = {62-66},
  volume   = {9},
  doi      = {10.1109/TSMC.1979.4310076},
  keywords = {Histograms;Marine vehicles;Radar tracking;Least squares approximation;Surveillance;Target tracking;Gaussian distribution;Displays;Q measurement;Sea measurements},
}

 
@Electronic{GpuGems3,
  author       = {Nolan Goodnight},
  howpublished = {GPU Gems 3},
  language     = {en-US},
  organization = {NVIDIA Corporation},
  title        = {{Part VI: GPU Computing}},
  url          = {https://developer.nvidia.com/gpugems/gpugems3/part-vi-gpu-computing},
  chapter      = {Part {VI}: {GPU} {Computing}},
  isbn         = {978-0321515261},
  pagetotal    = {942},
  ppn_gvk      = {1680473905},
  publisher    = {Addison-Wesley},
  shorttitle   = {Part {VI}},
}

@Comment{jabref-meta: databaseType:bibtex;}
